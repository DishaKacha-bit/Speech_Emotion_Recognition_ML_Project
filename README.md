This project focuses on building a Speech Emotion Recognition (SER) system using deep learning techniques. 
The primary goal is to identify human emotions through speech, leveraging variations in tone and pitch that often reveal emotional states. 
The project utilizes multiple datasets to train and evaluate various models, including CNN, LSTM, and a hybrid CNN+LSTM architecture.
